{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 total_devices  Rank\nPublisher                           \nGoogle Sites              5345   1.0\nFacebook                  4914   2.0\nAmazon Sites              1083   3.0\nSnapchat, Inc              823   4.0\nOath                       591   5.0\nPinterest                  533   6.0\nNetflix Inc.               433   7.0\nMicrosoft Sites            339   8.0\nWal-Mart                   310   9.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_devices</th>\n      <th>Rank</th>\n    </tr>\n    <tr>\n      <th>Publisher</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Google Sites</th>\n      <td>5345</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Facebook</th>\n      <td>4914</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>Amazon Sites</th>\n      <td>1083</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>Snapchat, Inc</th>\n      <td>823</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>Oath</th>\n      <td>591</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>Pinterest</th>\n      <td>533</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>Netflix Inc.</th>\n      <td>433</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>Microsoft Sites</th>\n      <td>339</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>Wal-Mart</th>\n      <td>310</td>\n      <td>9.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "user_activity=pd.read_csv('Dataset/User_activity.txt')\n",
    "device_demographics=pd.read_csv('Dataset/device_demographics.csv')\n",
    "publishers=pd.read_csv('Dataset/publishers.csv')\n",
    "\n",
    "user_activity_clean=user_activity.drop_duplicates().T\n",
    "user_device_demographics_merge=user_activity_clean.merge(device_demographics,on='device_id')\n",
    "user_device_publisher=user_device_demographics_merge.merge(publishers,on='app_name').drop_duplicates()\n",
    "user_device_publisher=user_device_publisher[['device_id','gender_id','app_name','minutes','Publisher']].sort_values(['app_name','minutes'])\n",
    "\n",
    "#### 5. Create an intermediate file (lookup file) using group by on column\n",
    "# 'app_name' and\n",
    "# 'Publisher' take the mode across gender id. E.g.\n",
    "\n",
    "app_publisher_gender=user_device_publisher.groupby(['app_name','Publisher'])['gender_id'].agg(pd.Series.mode)\n",
    "app_publisher_gender=pd.DataFrame(app_publisher_gender)\n",
    "\n",
    "#### 6. For any NaN values in the gender_id column,\n",
    "# replace missing values using the table created from step 5 ####\n",
    "user_device_publisher.loc[user_device_publisher['gender_id'].isnull(),'gender_id']=user_device_publisher[user_device_publisher['gender_id'].isnull()].apply(lambda row:app_publisher_gender.loc[(row['app_name'],row['Publisher']),'gender_id'],axis=1)\n",
    "\n",
    "#### 7. Create another intermediate file (lookup file) using group by on column 'app_name'\n",
    "# and 'Publisher' take the median across minutes column id.\n",
    "\n",
    "app_publisher_minutes=user_device_publisher.groupby(['app_name','Publisher'])['minutes'].agg(pd.Series.median)\n",
    "app_publisher_minutes=pd.DataFrame(app_publisher_minutes)\n",
    "\n",
    "\n",
    "#### 8. For any NaN values in the minute’s column, replace missing values using the table\n",
    "# created from step 7\n",
    "user_device_publisher.loc[user_device_publisher['minutes'].isnull(),'minutes']=user_device_publisher[user_device_publisher['minutes'].isnull()].apply(lambda row:app_publisher_minutes.loc[(row['app_name'],row['Publisher']),'minutes'],axis=1)\n",
    "\n",
    "#### 9. Filter the data across minutes column if the value is\n",
    "# greater than (median +\n",
    "# standard deviation) across app_name or\n",
    "# minutes value id less than 30 mins\n",
    "\n",
    "minutes_filter=user_device_publisher.groupby('app_name')['minutes'].agg(['median','std'])\n",
    "minutes_filter['sum']=minutes_filter['median']+minutes_filter['std']\n",
    "# minutes_filter\n",
    "\n",
    "convertdict = {'gender_id':int,'app_name':'string',\n",
    "               'minutes':float,'Publisher':'string'\n",
    "               }\n",
    "user_device_publisher=user_device_publisher.astype(convertdict)\n",
    "minutes_filter_2=user_device_publisher.apply(lambda row: True if (\n",
    "            minutes_filter.loc[row['app_name'], 'sum'] >= row['minutes'] > 30) else False, axis=1)\n",
    "user_device_publisher=user_device_publisher[minutes_filter_2]\n",
    "\n",
    "\n",
    "#### 10. Aggregate the from output to step 9 and\n",
    "# create a statistical dataset (as per 10.1 and\n",
    "# 10.2) with count, min, mean, Qaurtile1 (25 percentile),\n",
    "# median, Qaurtile2 (75\n",
    "# percentile), standard deviation, and max values\n",
    "# across App_Names, and across\n",
    "# “app_name + gender_id”\n",
    "# def percentile(n):\n",
    "#     def percentile_(x):\n",
    "#         return np.percentile(x, n)\n",
    "#     percentile_.__name__ = 'percentile_%s' % n\n",
    "#     return percentile_\n",
    "\n",
    "#10.1\n",
    "def Qaurtile1(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "def Qaurtile3(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "\n",
    "user_device_publisher_10=user_device_publisher.groupby('app_name')['minutes'].agg({'count','min','mean',Qaurtile1,'median',Qaurtile3,'std','max'})\n",
    "\n",
    "#10.2\n",
    "\n",
    "\n",
    "user_device_publisher_10_1= user_device_publisher.groupby(['app_name','gender_id'])['minutes'].agg({'count','min','mean','median','std','max'})\n",
    "\n",
    "# Load the data created in step 10 into the target system. (export it to CSV file)\n",
    "user_device_publisher_10.to_csv('step_10_csv')\n",
    "user_device_publisher_10_1.to_csv('step_10_1_csv')\n",
    "\n",
    "#### 11. Create a new data frame with columns as\n",
    "# app_name, “total_minutes”, “total\n",
    "#devices”, “Average Minutes per Device Per App”.\n",
    "# Use the below expression for\n",
    "#creating this column:\n",
    "\n",
    "def my_agg(x):\n",
    "    names = {\n",
    "        'total_minutes': x['minutes'].sum(),\n",
    "        'total_devices': x['device_id'].count(),\n",
    "        'avg_time_spend_per_device':x['minutes'].mean()\n",
    "    }\n",
    "\n",
    "    return pd.Series(names)\n",
    "\n",
    "user_device_publisher_new= user_device_publisher.groupby('app_name').apply(my_agg)\n",
    "\n",
    "#### 12. Use data generated in step 11 to create a ranking system\n",
    "# for Apps based on minutes spend over the app_name\n",
    "# and rank based on total users on different apps and load\n",
    "#the data into the target system\n",
    "# (a separate file for each ranking system)\n",
    "\n",
    "user_device_publisher_new['Rank_Duration_Based']=user_device_publisher_new['total_minutes'].rank()\n",
    "user_device_publisher_new['Rank_User_Based']=user_device_publisher_new['total_devices'].rank(ascending=False)\n",
    "sorted_data=user_device_publisher_new.sort_values(\"Rank_User_Based\",ascending=False)\n",
    "\n",
    "#### 13. Create and load files for Publisher Ranking as well\n",
    "\n",
    "def total_devices_agg(x):\n",
    "    names = {\n",
    "        'total_devices': x['device_id'].count(),\n",
    "    }\n",
    "\n",
    "    return pd.Series(names)\n",
    "user_device_publisher_13 = user_device_publisher.groupby('Publisher').apply(total_devices_agg)\n",
    "# user_device_publisher['total_devices'].rank()\n",
    "user_device_publisher_13['Rank']= user_device_publisher_13['total_devices'].rank(ascending=False)\n",
    "user_device_publisher_13=user_device_publisher_13.sort_values('total_devices',ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}